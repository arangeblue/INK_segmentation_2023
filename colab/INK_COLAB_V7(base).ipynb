{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMG1PkyQUdLvJWb2RnKZPSv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLcDKjW31C7_","executionInfo":{"status":"ok","timestamp":1686721498479,"user_tz":-540,"elapsed":4187,"user":{"displayName":"orangeblue","userId":"13763122058311192622"}},"outputId":"9548cc9f-cbbd-475b-f3d5-2cc75e9ce9fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["# !pip install timm\n","# !pip install imageio-ffmpeg\n","# !pip install segmentation-models-pytorch\n","# !pip install colorama\n","# !pip install einops\n","# !pip install statsmodels\n","# !pip install transformers\n","# !pip install kaggle\n","# !pip install --upgrade https://github.com/VincentStimper/mclahe/archive/numpy.zip -q\n","# # !pip install git+https://github.com/asullivan42/mclahe.git\n","# # # # # # !pip install torchsummary\n","# # # # # !pip install csbdeep"],"metadata":{"id":"nRIRLiG81PG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !cp /content/drive/MyDrive/kaggle_competitions/vision/INK_segmentation_2023/input/resnet3d.py /content/"],"metadata":{"id":"s2O6e9g2MRQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# utils\n","import os\n","import sys\n","import random\n","import tifffile\n","import gc\n","from glob import glob\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","import cv2\n","import PIL.Image as Image\n","Image.MAX_IMAGE_PIXELS = 10000000000\n","import collections\n","from einops import rearrange, reduce, repeat\n","\n","# augmentation\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.cuda import amp\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","# import torchsummary\n","\n","# scipy stat\n","import scipy\n","from scipy.stats import median_abs_deviation\n","\n","\n","#model\n","sys.path.append('/content/drive/MyDrive/kaggle_competitions/vision/INK_segmentation_2023/input')\n","from resnet3d import generate_model\n","import segmentation_models_pytorch as smp\n","from timm.models.resnet import *\n","import timm\n","from segmentation_models_pytorch.decoders.unet.decoder import UnetDecoder, DecoderBlock\n","\n","# kfold\n","from sklearn.model_selection import KFold\n","\n","# gauss filter - median\n","from scipy.ndimage import gaussian_filter\n","\n","\n","# 3d-clahe\n","import mclahe as mc\n","import tensorflow\n","\n","# color font\n","from colorama import Fore, Back, Style\n","r_ = Fore.RED\n","b_ = Fore.BLUE\n","c_ = Fore.CYAN\n","g_ = Fore.GREEN\n","y_ = Fore.YELLOW\n","m_ = Fore.MAGENTA\n","sr_ = Style.RESET_ALL\n","\n","from typing import Dict\n","from google.colab import _debugpy_repr\n","import scipy.io\n","\n","class dotdict(dict):\n","    def __getattr__(self, item):\n","        try:\n","            return self[item]\n","        except KeyError as e:\n","            raise AttributeError from e\n","\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","a=1\n","b=1\n","d = dotdict(a=b)\n","_debugpy_repr.get_shape(d)"],"metadata":{"id":"HoXXKBNL2H2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !mkdir /root/.kaggle\n","# !cp /content/drive/MyDrive/kaggle_competitions/kaggle.json /root/.kaggle  # kaggl.json위치 지정\n","# !chmod 600 /root/.kaggle/kaggle.json\n","# !kaggle competitions download -c vesuvius-challenge-ink-detection\n","\n","# !unzip -qq  /content/vesuvius-challenge-ink-detection.zip"],"metadata":{"id":"2T5CN1RQ2o8i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CFG(object):\n","\n","    # 2 -> 14830, 9506,\n","\n","    crop_size = 224\n","    crop_fade = crop_size//4\n","    crop_stride = crop_size//2\n","    num_concat = 2\n","    crop_depth = 5\n","    train_fragment_z = [18, 42] # 20 range ->  16+17, 17+18\n","    infer_fragment_z = [18, 42]\n","    train_fragment_depth = train_fragment_z[1] - train_fragment_z[0]\n","    infer_fragment_depth = infer_fragment_z[1] - infer_fragment_z[0]\n","\n","    is_tta = True\n","\n","    train_batch_size = 32\n","    valid_batch_size = 32\n","    max_grad_norm = 1000\n","    accumulate_iter = 2\n","\n","\n","    lr = 1e-3\n","    wd = 1e-4\n","    eps = 1e-6\n","    num_epochs = 50\n","    patience = 6\n","    num_workers = 1\n","    batch_scheduler = True\n","    seed = 2023\n","    date = datetime.now().strftime(\"%Y%m%d\")\n","    model_name = \"colabv7_resnet34d_unet_stride\"\n","    # model_name = \"colabv4_seresnext26t_32x4d_unet\"\n","    train_model_name = 'resnet34d'\n","    # train_model_name = 'seresnext26t_32x4d'\n","    # \"seresnext26t_32x4d\"\n","\n","    train_fragment = np.array(['1a',\"1b\",\"3\",\"2e\",\"2f\"])\n","    valid_fragment = \"1\"\n","    n_splits = len(train_fragment)\n","\n","    colab_dir = '/content/drive/MyDrive/kaggle_competitions/vision/INK_segmentation_2023'\n","\n","    train_dir = '/content/train'\n","    mask_dir = colab_dir + \"/input\"\n","    private_dir =  colab_dir + \"/input\"\n","\n","    mode = [\n","        'train', #\n","#         'test', 'skip_fake_test',\n","    ]\n","\n","    device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","# os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n","\n","\n","\n","cfg = CFG()\n","\n","if 'train' in cfg.mode:\n","    data_dir = '/content/train'\n","    valid_id =[\n","        '1',#'2b',\n","    ]\n","\n","\n","print('data_dir', data_dir)\n","print('valid_id', valid_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJ3BUSR72eWh","executionInfo":{"status":"ok","timestamp":1686721517539,"user_tz":-540,"elapsed":1305,"user":{"displayName":"orangeblue","userId":"13763122058311192622"}},"outputId":"93c9ea9a-0c4e-45c0-824c-9b11b9182028"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data_dir /content/train\n","valid_id ['1']\n"]}]},{"cell_type":"code","source":["def pixel_clipping(img, low_b, high_b):\n","    img = np.array(img)\n","    display(f\"img mean : {img.mean()}, img mean : {img.max()}, img mean : {img.min()}\")\n","\n","    lo_pct, hi_pct = 5.0, 95.0\n","    lo_val, hi_val = np.percentile(img, [lo_pct, hi_pct])\n","    new_img = np.clip(img, lo_val, hi_val)\n","    new_img = ((new_img - new_img.min()) * 255.0 / (new_img.max() - new_img.min())).astype(np.uint8)\n","    display(f\"new img mean : {new_img.mean()}, new img mean : {new_img.max()}, new img mean : {new_img.min()}\")\n","\n","    return new_img\n","\n","def median_state(volume_img, volume_mask):\n","    eps = 1e-7\n","    h,w,c = volume_img.shape\n","    volume_img = volume_img.transpose(2,0,1) # [c, h, w]\n","    median = np.median(volume_img[:,volume_mask.astype(bool)], axis=1, overwrite_input=False)\n","    mad = np.median(\n","        np.abs(volume_img[:,volume_mask.astype(bool)].T - median),\n","         axis=0, overwrite_input=True)\n","\n","    return median, mad\n","\n","def median_normalize(volume_img, volume_mask):\n","    \"\"\"\n","    img = [h,w,c]\n","    \"\"\"\n","    # median_scale\n","    eps = 1e-8\n","    h,w,c = volume_img.shape\n","    volume_img = volume_img.transpose(2,0,1) # [c, h, w]\n","    median = np.median(volume_img[:,volume_mask.astype(bool)], axis=1, overwrite_input=False).astype(np.float16)\n","    mad = np.median(\n","        np.abs(volume_img[:,volume_mask.astype(bool)].T - median),\n","         axis=0, overwrite_input=True).astype(np.float16)\n","    imgs = np.zeros((h,w,c), dtype=np.float16)\n","    for i in tqdm(range(c)):\n","        imgs[...,i] = ((volume_img[i] - median[i]) / (mad[i] + eps))\n","#     imgs = imgs.astype(np.uint8)\n","    # imgs = np.stack(imgs, axis=2) # [h,w,c]\n","\n","    # minmax\n","    # max = imgs.max()\n","    # min = imgs.min()\n","    # imgs = ((imgs - min) / (max - min))\n","    return imgs"],"metadata":{"id":"Utd_3bS2rJ4T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ordering\n","\n","1. 모든 layer load\n","2. cliping\n","3. 원하는 layer 선택\n","4. train\n"],"metadata":{"id":"r0b1osZLzKpe"}},{"cell_type":"code","source":["image_map = {\n","    '1': {'h': 8181, 'w': 6330},\n","    '2': {'h': 14830, 'w': 9506},\n","    '3': {'h': 7606, 'w': 5249}\n","    }"],"metadata":{"id":"cXM7RUbHz6LQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def do_3dcleha(images):\n","        \"\"\"\n","        image shape :  c, h, w\n","        tensor\n","        \"\"\"\n","\n","        images  = mc.mclahe(images, kernel_size=[5,8,8],\n","                n_bins=64,\n","                clip_limit=0.01,\n","                adaptive_hist_range=False,\n","                )\n","\n","        return images\n","\n","def timer():\n","    now = time.time()\n","    return now\n","\n","def do_binary(mask, thr=0.5):\n","    mask = mask-mask.min()\n","    mask = mask/(mask.max()+1e-7)\n","    mask = (mask>thr).astype(np.float32) # np.float32\n","\n","    return mask\n","\n","def read_data(fragment_id, z0=cfg.train_fragment_z[0], z1=cfg.train_fragment_z[1]):\n","    start_timer = timer()\n","\n","    # full load\n","    images = []\n","    for i in range(z0, z1):\n","        image = cv2.imread(f\"{data_dir}/{fragment_id}/surface_volume/{i:02d}.tif\",0)\n","        # image = (image>>8).astype(np.uint8)\n","        images.append(image)\n","\n","        print(f'\\r @ read_data(): images{fragment_id}  {f\"{timer() - start_timer}\"+ \"sec\"}', end='', flush=True)\n","\n","    images = np.stack(images, 2)\n","\n","    mask = cv2.imread(f\"{cfg.mask_dir}/{fragment_id}_adjusted_mask.png\", cv2.IMREAD_GRAYSCALE)\n","    images[mask == 0] = 0\n","    mask = do_binary(mask)\n","\n","    # del images_\n","\n","    if 'train' in cfg.mode:\n","#         ir = cv2.imread(f'{data_dir}/{fragment_id}/ir.png', cv2.IMREAD_GRAYSCALE)\n","        # label = cv2.imread(f'{data_dir}/{fragment_id}/inklabels.png', cv2.IMREAD_GRAYSCALE)\n","        label = cv2.imread(f\"{cfg.private_dir}/new_inklabel{fragment_id}.png\",cv2.IMREAD_GRAYSCALE)\n","#         ir = ir / 255.0\n","        label = do_binary(label)\n","\n","    if 'test' in cfg.mode:\n","        ir = None\n","        label = None\n","\n","    dic = dotdict(\n","        fragment_id = fragment_id,\n","        images = images,\n","#         ir = ir,\n","        label = label,\n","        mask = mask\n","    )\n","\n","\n","    gc.collect()\n","    return dic\n","\n","def read_dic(fragment_id):\n","    if fragment_id == \"2a\":\n","        y = 7050\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2a',\n","            images = dic.images[:y],\n","#             ir = dic.ir[:y],\n","            label = dic.label[:y],\n","            mask = dic.mask[:y]\n","        )\n","    elif fragment_id==\"2b\":\n","        y0,y1 = 7050, 10500\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2b',\n","            images = dic.images[y0:y1],\n","#             ir = dic.ir[y:],\n","            label = dic.label[y0:y1],\n","            mask = dic.mask[y0:y1]\n","        )\n","    elif fragment_id==\"2c\":\n","        y = 10500\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2c',\n","            images = dic.images[y:],\n","#             ir = dic.ir[y:],\n","            label = dic.label[y:],\n","            mask = dic.mask[y:]\n","        )\n","    elif fragment_id==\"2d\":\n","        y0,y1 = 0, 7074\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2d',\n","            images = dic.images[y0:y1],\n","#             ir = dic.ir[y:],\n","            label = dic.label[y0:y1],\n","            mask = dic.mask[y0:y1]\n","        )\n","\n","    elif fragment_id==\"2e\":\n","        y = 9456\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2d',\n","            images = dic.images[:y],\n","#             ir = dic.ir[y:],\n","            label = dic.label[:y],\n","            mask = dic.mask[:y]\n","        )\n","    elif fragment_id==\"2f\":\n","        y = 9456\n","        dic = read_data('2')\n","        dic = dotdict(\n","            fragment_id = '2f',\n","            images = dic.images[y:],\n","#             ir = dic.ir[y:],\n","            label = dic.label[y:],\n","            mask = dic.mask[y:]\n","        )\n","\n","    elif fragment_id==\"1a\":\n","        y = 2600\n","        dic = read_data('1')\n","        dic = dotdict(\n","            fragment_id = '1a',\n","            images = dic.images[:y],\n","#             ir = dic.ir[y:],\n","            label = dic.label[:y],\n","            mask = dic.mask[:y]\n","        )\n","\n","    elif fragment_id==\"1b\":\n","        y = 2600\n","        dic = read_data('1')\n","        dic = dotdict(\n","            fragment_id = '1b',\n","            images = dic.images[y:],\n","#             ir = dic.ir[y:],\n","            label = dic.label[y:],\n","            mask = dic.mask[y:]\n","        )\n","\n","\n","    elif fragment_id==\"3\":\n","#         y = 9456\n","        dic = read_data('3')\n","        dic = dotdict(\n","            fragment_id = '3',\n","            images = dic.images,\n","#             ir = dic.ir[y:],\n","            label = dic.label,\n","            mask = dic.mask\n","        )\n","\n","    else:\n","        dic = read_data(fragment_id)\n","\n","    gc.collect()\n","    return dic"],"metadata":{"id":"zxBkoavx4XNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = read_dic(\"1\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wWe_0MlVlXB","executionInfo":{"status":"ok","timestamp":1686721550100,"user_tz":-540,"elapsed":31592,"user":{"displayName":"orangeblue","userId":"13763122058311192622"}},"outputId":"29e1e7ba-569b-49dd-8053-b5e2a0f72b4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" @ read_data(): images1  24.301363229751587sec"]}]},{"cell_type":"code","source":["def run_check_data():\n","    dic=read_dic(valid_id[0])#valid_id[0]\n","    display('')\n","    display('fragment_id:', dic.fragment_id)\n","    display('images:', dic.images.shape, dic.images.min(), dic.images.max())\n","#     display('mask  :', dic.mask.shape, dic.mask.min(), dic.mask.max())\n","    if 'train' in cfg.mode:\n","        display('ir    :', dic.ir.shape, dic.ir.min(), dic.ir.max())\n","        display('label :', dic.label.shape, dic.label.min(), dic.label.max())\n","\n","# run_check_data()\n","print('data ok !!!')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C59LuQHS5LtF","executionInfo":{"status":"ok","timestamp":1686721550747,"user_tz":-540,"elapsed":23,"user":{"displayName":"orangeblue","userId":"13763122058311192622"}},"outputId":"85aeafeb-308f-4428-dd12-79298bfb5a50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data ok !!!\n"]}]},{"cell_type":"code","source":["def get_train_transforms():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","        A.Flip(p=0.5),\n","        A.OneOf([\n","            A.Sharpen(alpha=0.1, lightness=0.1, p=0.3),\n","            # A.RandomGamma(gamma_limit=(50,100), p=0.3),\n","            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15,p=0.3),\n","        ],p=0.4),\n","        A.ShiftScaleRotate(\n","            shift_limit=0.1,\n","            scale_limit=0.1,\n","            rotate_limit=0,\n","            p=0.5),\n","        A.Transpose(p=0.2),\n","        A.OneOf([\n","                A.GaussNoise(var_limit=0.08, p=0.5), # var_limit=[2, 10]\n","                A.GaussianBlur(p=0.2),\n","                A.MotionBlur(p=0.2),\n","                # A.ISONoise(color_shift=(0.01,0.03), intensity=(0.1,0.2)),\n","                A.MedianBlur(blur_limit=5, p=0.3),\n","                A.MultiplicativeNoise(multiplier=(0.9,1.1), p=0.1),\n","                ], p=0.5),\n","\n","        A.OneOf([\n","                A.OpticalDistortion(p=0.2),\n","                A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.5),\n","                A.Affine(p=0.2),\n","                A.RandomGridShuffle(grid=(2,2), p=0.2),\n","                A.PiecewiseAffine(p=0.1),\n","        ], p=0.5),\n","\n","        A.OneOf([\n","#             A.Cutout(p=0.3, num_holes=4, max_h_size=int(CFG.crop_size * 0.2), max_w_size=int(CFG.crop_size * 0.2)),\n","            A.CoarseDropout(max_holes=2, max_width=int(cfg.crop_size * 0.2), max_height=int(cfg.crop_size * 0.2),\n","                        mask_fill_value=0, p=0.3),\n","            A.GridDropout(ratio=0.1, random_offset=True, mask_fill_value=0, p=0.3),\n","        ], p=0.4),\n","\n","        A.Normalize(mean=[0]*cfg.train_fragment_depth, std=[1]*cfg.train_fragment_depth),\n","        ToTensorV2(transpose_mask=True)\n","    ], additional_targets={'mask1': 'mask'})\n","\n","def get_valid_transforms():\n","    return A.Compose([\n","        A.Normalize(mean=[0]*cfg.train_fragment_depth, std=[1]*cfg.train_fragment_depth),\n","        ToTensorV2(transpose_mask=True)\n","    ],  additional_targets={'mask1': 'mask'})"],"metadata":{"id":"kATJkdgT5MvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomTrainDataset(Dataset):\n","    def __init__(self, fragment_id, transforms = None):\n","        self.fragment_id = fragment_id\n","        self.transforms = transforms\n","        self.norm_transform = A.Compose([\n","            A.Normalize(mean=[0]*cfg.train_fragment_depth, std=[1]*cfg.train_fragment_depth),\n","            ToTensorV2(transpose_mask=True)\n","        ],p=1, additional_targets={\"mask1\" : \"mask\"})\n","\n","        self.xys = []\n","        self.xyss = None\n","        self.dics = {}\n","\n","        for fragment in fragment_id:\n","\n","            self.dics[fragment] = read_dic(fragment)\n","            H,W,C = self.dics[fragment]['images'].shape\n","            imgs = []\n","            for i in range(C):\n","                pad0 = (cfg.crop_stride - H % cfg.crop_stride)\n","                pad1 = (cfg.crop_stride - W % cfg.crop_stride)\n","                img = np.pad(self.dics[fragment]['images'][:,:,i], [(0, pad0), (0, pad1)], constant_values=0)\n","                imgs.append(img)\n","            imgs = np.stack(imgs, axis=2)\n","            self.dics[fragment]['images'] = imgs\n","            H,W,C = self.dics[fragment]['images'].shape\n","\n","            for y in range(0, H-cfg.crop_size+1, cfg.crop_size):\n","                for x in range(0, W-cfg.crop_size+1, cfg.crop_size):\n","                    self.xys.append((fragment, x, y, W, H))\n","\n","            self.dics[fragment]['label'] = np.pad(self.dics[fragment]['label'], [(0, pad0), (0, pad1)], constant_values=0)\n","            self.dics[fragment]['mask'] = np.pad(self.dics[fragment]['mask'], [(0, pad0), (0, pad1)], constant_values=0)\n","\n","        self.xyss = self.filter_empty_label(self.xys)\n","\n","    def __len__(self):\n","        return len(self.xyss)\n","\n","\n","    def __getitem__(self, idx):\n","\n","        fragment, x1, y1, W, H = self.xyss[idx]\n","\n","\n","        # augment\n","        if np.random.rand()<0.7:\n","            if np.random.rand()<0.7:\n","                frag_crop, label_crop, mask_crop, crop_x1,crop_y1 = self.do_random_crop(\n","                self.dics[fragment]['images'],\n","                self.dics[fragment]['label'],\n","                self.dics[fragment]['mask'],\n","                crop_size=cfg.crop_size,\n","                valid_mask_threshold=0.8)\n","\n","                x2 = crop_x1 + cfg.crop_size\n","                y2 = crop_y1 + cfg.crop_size\n","\n","\n","            else:\n","\n","                x2 = x1 + cfg.crop_size\n","                y2 = y1 + cfg.crop_size\n","\n","                frag_crop = self.dics[fragment]['images'][y1:y2, x1:x2, :]\n","                label_crop = self.dics[fragment]['label'][y1:y2, x1:x2]\n","                mask_crop = self.dics[fragment]['mask'][y1:y2, x1:x2]\n","\n","            frag_crop = np.ascontiguousarray(frag_crop)\n","            label_crop = np.ascontiguousarray(label_crop)\n","            mask_crop = np.ascontiguousarray(mask_crop)\n","\n","\n","            if self.transforms is not None:\n","                data = self.transforms(image=frag_crop, mask=label_crop, mask1=mask_crop)\n","                images = data['image']\n","                labels = data['mask']\n","                masks = data['mask1']\n","\n","        else:\n","\n","            if np.random.rand()<0.7:\n","                # crop_types = ['mask','label']\n","                # crop_type = np.random.choice(crop_types)\n","                frag_crop, label_crop, mask_crop, crop_x1,crop_y1 = self.do_random_crop(\n","                self.dics[fragment]['images'],\n","                self.dics[fragment]['label'],\n","                self.dics[fragment]['mask'],\n","                crop_size=cfg.crop_size,\n","                valid_mask_threshold=0.8)\n","\n","                x2 = crop_x1 + cfg.crop_size\n","                y2 = crop_y1 + cfg.crop_size\n","\n","            else:\n","                x2 = x1 + cfg.crop_size\n","                y2 = y1 + cfg.crop_size\n","                frag_crop = self.dics[fragment]['images'][y1:y2, x1:x2, :]\n","                label_crop = self.dics[fragment]['label'][y1:y2, x1:x2]\n","                mask_crop = self.dics[fragment]['mask'][y1:y2, x1:x2]\n","\n","            if np.random.rand()<0.5:\n","                frag_crop = cv2.flip(frag_crop, 1)\n","                label_crop = cv2.flip(label_crop, 1)\n","                mask_crop = cv2.flip(mask_crop, 1)\n","\n","            if np.random.rand()<0.5:\n","                frag_crop = cv2.flip(frag_crop, 0)\n","                label_crop = cv2.flip(label_crop, 0)\n","                mask_crop = cv2.flip(mask_crop, 0)\n","\n","            if np.random.rand()<0.4:\n","                n = np.random.choice(4)\n","                frag_crop = np.rot90(frag_crop, n, axes=(0,1))\n","                label_crop = np.rot90(label_crop, n, axes=(0,1))\n","                mask_crop = np.rot90(mask_crop, n, axes=(0,1))\n","\n","            if np.random.rand()<0.4:\n","                type_list = [\"gauss\", \"poisson\",\"speckle\"]\n","                noise_type = np.random.choice(type_list)\n","                frag_crop = self.do_random_noise(frag_crop, noise_type)\n","\n","            frag_crop = np.ascontiguousarray(frag_crop)\n","            label_crop = np.ascontiguousarray(label_crop)\n","            mask_crop = np.ascontiguousarray(mask_crop)\n","\n","            data = self.norm_transform(image=frag_crop, mask=label_crop, mask1=mask_crop)\n","            images = data['image']\n","            labels = data['mask']\n","            masks = data['mask1']\n","\n","        return {\"images\":  images ,# .type(torch.FloatTensor)\n","                \"labels\" : labels,\n","                \"masks\" : masks,\n","                \"xys\" : torch.tensor([x1, y1, x2, y2], dtype=torch.int32)\n","               }\n","\n","\n","    def filter_empty_label(self,xyss):\n","        new_xys = []\n","        for xys in tqdm(xyss):\n","            fragment, x1, y1, W, H = xys\n","            x = x1\n","            y = y1\n","\n","            x2 = x1 + cfg.crop_size\n","            y2 = y1 + cfg.crop_size\n","\n","            mask_crop = self.dics[fragment]['mask'][y1:y2, x1:x2]\n","            if mask_crop.mean()>0.05:\n","                new_xys.append((fragment, x, y, W, H))\n","\n","        return new_xys\n","\n","    def do_random_crop(\n","        self,\n","        image,\n","        label,\n","        mask,\n","        crop_size=cfg.crop_size,\n","        valid_mask_threshold=0.8\n","    ):\n","        height, width = image.shape[:2]\n","        while (1):\n","            y = np.random.randint(0, height - crop_size+1)\n","            x = np.random.randint(0, width  - crop_size+1)\n","            crop_image = image[y:y + crop_size, x:x + crop_size,:]\n","            crop_mask  = mask[y:y + crop_size, x:x + crop_size]\n","            crop_label  = label[y:y + crop_size, x:x + crop_size]\n","\n","            if crop_mask.mean() > valid_mask_threshold:\n","                break\n","\n","        return crop_image, crop_label, crop_mask, x, y\n","\n","\n","    def do_equalize(self, images):\n","        \"\"\"\n","        input shape : [h,w,c]\n","        \"\"\"\n","        images = images.transpose(2,0,1)\n","        images = np.stack([cv2.equalizeHist(image) for image in images],-1)\n","\n","        return images\n","\n","    def do_clahe(self, images):\n","        \"\"\"\n","        input shape  : [h,w,c]\n","        \"\"\"\n","        images = images.transpose(2,0,1) # 224, 224\n","        limit_list = [2, 4]\n","        grid_list = [2,4,8]\n","        limit = np.random.choice(limit_list,1)\n","        grid = np.random.choice(grid_list,1)\n","        clahe  = cv2.createCLAHE(clipLimit=limit[0], tileGridSize=(grid[0],grid[0]))\n","        images = np.stack([clahe.apply(image) for image in images], -1)\n","\n","        return images\n","\n","    def do_random_noise(self, images, noise_type):\n","        if noise_type == \"gauss\":\n","            row,col,ch= images.shape\n","            mean = 0\n","            var = 0.1\n","            sigma = var**0.5\n","            gauss = np.random.normal(mean,sigma,(row,col,ch))\n","            gauss = gauss.reshape(row,col,ch)\n","            noisy = images + gauss\n","            return noisy\n","        elif noise_type == \"poisson\":\n","            vals = len(np.unique(images))\n","            vals = 2 ** np.ceil(np.log2(vals))\n","            noisy = np.random.poisson(images * vals) / float(vals)\n","            return noisy\n","        elif noise_type ==\"speckle\":\n","            row,col,ch = images.shape\n","            gauss = np.random.randn(row,col,ch)\n","            gauss = gauss.reshape(row,col,ch)\n","            noisy = images + images * gauss\n","            return noisy\n","\n","    def do_3dcleha(self, images):\n","        \"\"\"\n","        image shape : h,w,c or c, h, w\n","        tensor\n","        \"\"\"\n","\n","        images = images.permute(2,0,1) # 224, 224\n","        images = images.numpy()\n","        images  = mc.mclahe(images, kernel_size=[4,4,4],\n","                n_bins=64,\n","                clip_limit=0.01,\n","                adaptive_hist_range=False,\n","\n","                )\n","        images = torch.tensor(images, dtype=torch.float32)\n","        images = images.permute(1,2,0)\n","        return images\n","\n","\n","class CustomValidDataset(Dataset):\n","    def __init__(self, fragment_id, transforms = None):\n","        self.fragment_id = fragment_id\n","        self.transforms = transforms\n","        self.xys = []\n","        self.dics = {}\n","\n","        for fragment in fragment_id:\n","            self.dics[fragment] = read_dic(fragment)\n","            H,W,C = self.dics[fragment]['images'].shape\n","            imgs = []\n","            for i in range(C):\n","                pad0 = (cfg.crop_stride - H % cfg.crop_stride)\n","                pad1 = (cfg.crop_stride - W % cfg.crop_stride)\n","                img = np.pad(self.dics[fragment]['images'][:,:,i], [(0, pad0), (0, pad1)], constant_values=0)\n","                imgs.append(img)\n","            imgs = np.stack(imgs, axis=2)\n","            self.dics[fragment]['images'] = imgs\n","\n","            H,W,C = self.dics[fragment]['images'].shape\n","\n","            for y in range(0, H-cfg.crop_size+1, cfg.crop_stride):\n","                for x in range(0, W-cfg.crop_size+1, cfg.crop_stride):\n","                    self.xys.append((fragment, x, y, W, H))\n","\n","            self.dics[fragment]['label'] = np.pad(self.dics[fragment]['label'], [(0, pad0), (0, pad1)], constant_values=0)\n","            self.dics[fragment]['mask'] = np.pad(self.dics[fragment]['mask'], [(0, pad0), (0, pad1)], constant_values=0)\n","\n","    def __len__(self):\n","        return len(self.xys)\n","\n","    def __getitem__(self, idx):\n","        fragment, x1, y1, W, H = self.xys[idx]\n","\n","        x2 = x1 + cfg.crop_size\n","        y2 = y1 + cfg.crop_size\n","\n","        frag_crop = self.dics[fragment]['images'][y1:y2, x1:x2, :]\n","        label_crop = self.dics[fragment]['label'][y1:y2, x1:x2]\n","        mask_crop = self.dics[fragment]['mask'][y1:y2, x1:x2]\n","\n","        # augment\n","        if self.transforms is not None:\n","            data = self.transforms(image=frag_crop, mask=label_crop, mask1=mask_crop)\n","            images = data['image']\n","            labels = data['mask']\n","            masks = data['mask1']\n","\n","        return {\"images\": images.type(torch.FloatTensor) , # .type(torch.FloatTensor)\n","                \"labels\" : labels,\n","                \"masks\" : masks,\n","                \"xys\" : torch.tensor([x1, y1, x2, y2], dtype=torch.int32)\n","               }\n","\n","    def do_equalize(self, images):\n","        \"\"\"\n","        input shape : [h,w,c]\n","        \"\"\"\n","        images = images.transpose(2,0,1)\n","        images = np.stack([cv2.equalizeHist(image) for image in images],-1)\n","\n","        return images\n","\n","    def do_clahe(self, images):\n","        \"\"\"\n","        input shape  : [h,w,c]\n","        \"\"\"\n","        limit_list = [2, 4]\n","        grid_list = [2,4,8]\n","        limit = np.random.choice(limit_list,1)\n","        grid = np.random.choice(grid_list,1)\n","        clahe  = cv2.createCLAHE(clipLimit=limit[0], tileGridSize=(grid[0],grid[0]))\n","        images = np.stack([clahe.apply(image) for image in images], -1)\n","\n","        return images\n","\n","    def do_3dcleha(self, images):\n","            \"\"\"\n","            tensor\n","            image shape : h,w,c or c, h, w\n","            \"\"\"\n","            images = images.permute(2,0,1) # 224, 224\n","            images = images.numpy()\n","            images  = mc.mclahe(images, kernel_size=[4,4,4],\n","                    n_bins=64,\n","                    clip_limit=0.01,\n","                    adaptive_hist_range=False,\n","                    )\n","\n","            images = torch.tensor(images, dtype=torch.float32)\n","            images = images.permute(1,2,0)\n","            return images\n","\n","def collate_fn(batch):\n","    return {\n","        'images': torch.stack([x['images'] for x in batch]),\n","        'labels': torch.stack([x['labels'] for x in batch]),\n","        'masks': torch.stack([x['masks'] for x in batch]),\n","        'xys'   : torch.stack([x['xys'] for x in batch])\n","}"],"metadata":{"id":"a8hNwlXW5X0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataloader test\n","# train_dataset = CustomTrainDataset(\"1\", get_train_transforms())\n","# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n","# data = next(iter(train_loader))\n"],"metadata":{"id":"wqRxU09uoYd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for i, data in enumerate(train_loader):\n","#     print(f\"{i+1} / {len(train_loader)}\")\n","#     print(len(data))\n","#     for j in range(len(data['images'])):\n","#         plt.figure(figsize=(12,8))\n","#         plt.subplot(1,3,1)\n","#         plt.imshow(data['images'][j][0])\n","#         plt.subplot(1,3,2)\n","#         plt.imshow(data['labels'][j], vmin=0, vmax=1)\n","#         plt.subplot(1,3, 3)\n","#         plt.imshow(data['masks'][j], vmin=0, vmax=1)\n","#         plt.title(f\"mask size : {data['masks'][j].mean()}\")\n","#         plt.show()"],"metadata":{"id":"G9ihwPRH-2RT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"_hpf_0cU6LUE"}},{"cell_type":"code","source":["# model\n","class SmpUnetDecoder(nn.Module):\n","    def __init__(self,\n","             in_channel,\n","             skip_channel,\n","             out_channel,\n","        ):\n","        super().__init__()\n","        self.center = nn.Identity()\n","\n","        i_channel = [in_channel,]+ out_channel[:-1]\n","        s_channel = skip_channel\n","        o_channel = out_channel\n","        block = [\n","            DecoderBlock(i, s, o, use_batchnorm=True, attention_type=None)\n","            for i, s, o in zip(i_channel, s_channel, o_channel)\n","        ]\n","        self.block = nn.ModuleList(block)\n","\n","    def forward(self, feature, skip):\n","        d = self.center(feature)\n","        decode = []\n","        for i, block in enumerate(self.block):\n","            s = skip[i]\n","            d = block(d, s)\n","            decode.append(d)\n","\n","        last  = d\n","        return last, decode\n","\n","\n","class Net(nn.Module):\n","    def __init__(self, ):\n","        super().__init__()\n","\n","        # --------------------------------\n","        self.crop_depth = cfg.crop_depth\n","\n","        conv_dim = 64\n","        encoder_dim = [conv_dim, 64, 128, 256, 512]\n","        decoder_dim = [256, 128, 64, 32, 16 ]\n","        self.encoder = resnet34d(pretrained=True, in_chans=self.crop_depth, drop_rate=0.5)\n","\n","        self.decoder = SmpUnetDecoder(\n","            in_channel=encoder_dim[-1],\n","            skip_channel=encoder_dim[:-1][::-1] + [0],\n","            out_channel=decoder_dim,\n","        )\n","        self.logit = nn.Conv2d(decoder_dim[-1], 1, kernel_size=1)\n","\n","        # aux\n","        self.aux = nn.ModuleList([\n","            nn.Conv2d(encoder_dim[i], 1, kernel_size=1, padding=0) for i in range(len(encoder_dim))\n","        ])\n","\n","        # attentin pool\n","        self.weight = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(dim, dim, kernel_size=3, padding=1),\n","                nn.ReLU(inplace=True),\n","            ) for dim in encoder_dim\n","        ])\n","\n","        # dropout layer\n","        self.dropout1 = nn.Dropout(0.5)\n","\n","    def forward(self, batch):\n","        v = batch['images']\n","        B, C, H, W = v.shape\n","        vv = [\n","            v[:, i:i + self.crop_depth] for i in range(0,C-self.crop_depth+1,2)\n","        ]\n","        K = len(vv)\n","        x = torch.cat(vv, 0)\n","\n","        # ---------------------------------\n","\n","        encoder = []\n","\n","        e = self.encoder\n","\n","        x = e.conv1(x)\n","        x = e.bn1(x)\n","        x = e.act1(x)\n","        encoder.append(x)\n","        x = F.avg_pool2d(x, kernel_size=2, stride=2)\n","        x = e.layer1(x); encoder.append(x);\n","        x = e.layer2(x); encoder.append(x);\n","        x = e.layer3(x); encoder.append(x);\n","        x = e.layer4(x); encoder.append(x);\n","\n","        # torch.Size([14, 64, 112, 112]) x\n","        # torch.Size([14, 64, 56, 56]) x pool\n","        # torch.Size([14, 256, 56, 56])x1\n","        # torch.Size([14, 512, 28, 28])x2\n","        # torch.Size([14, 1024, 14, 14])x3\n","        # torch.Size([14, 2048, 7, 7]) x 4\n","        # torch.Size([14, 64, 112, 112]) e\n","        # torch.Size([14, 256, 56, 56]) e\n","\n","        for i in range(len(encoder)):\n","            e = encoder[i]\n","            _, c, h, w = e.shape # k b 512, 7, 7\n","            e = rearrange(e, '(K B) c h w -> K B c h w', K=K, B=B, h=h, w=w)\n","\n","            encoder[i] = e.mean(0)\n","\n","\n","        last, decoder = self.decoder(feature = encoder[-1], skip = encoder[:-1][::-1]  + [None])\n","\n","\n","        # ---------------------------------\n","        logit = self.logit(last)\n","\n","        output = {}\n","        output['logit'] = logit\n","\n","        if 1:\n","            if logit.shape[2:]!=(H, W):\n","                logit = F.interpolate(logit, size=(H, W), mode='bilinear', align_corners=False, antialias=True)\n","            output['ink'] = torch.sigmoid(logit)\n","\n","        return output"],"metadata":{"id":"uozbZAkW6H7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model I/O test\n","\n","# batch = {\n","#         'images' : torch.from_numpy( np.random.choice(256, (1, cfg.train_fragment_depth, 224, 224))).float(),\n","#     }\n","\n","# model = Net()\n","# model(batch)['logit'].shape"],"metadata":{"id":"hDE2rrqckwzh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Metric and Losses"],"metadata":{"id":"FnLvZQwc6R2w"}},{"cell_type":"code","source":["class CompoundLoss(nn.Module):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        # self.diceloss= smp.losses.DiceLoss(mode='binary', from_logits=True)\n","        self.bceloss = smp.losses.SoftBCEWithLogitsLoss()\n","        # self.bceloss = torch.nn.BCEWithLogitsLoss()\n","        self.bceloss.__name__ = 'bce_loss'\n","\n","    def forward(self, y_pr, y_gt):\n","        return self.bceloss.forward(y_pr,y_gt)\n","        # return self.diceloss.forward(y_pr, y_gt)\n","        # return (self.bceloss.forward(y_pr, y_gt) + self.diceloss.forward(y_pr, y_gt)) / 2\n","        # return 0.7 * self.diceloss.forward(y_pr, y_gt) + 0.3 * self.bceloss.forward(y_pr, y_gt)\n","\n","class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceBCELoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        # inputs = F.sigmoid(inputs)\n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n","        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","\n","        return Dice_BCE\n","\n","class FocalTverskyLoss(nn.Module):\n","    def __init__(self, alpha, beta, gamma, smooth, weight=None, size_average=True):\n","        super(FocalTverskyLoss, self).__init__()\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.smooth = smooth\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)\n","\n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        #True Positives, False Positives & False Negatives\n","        TP = (inputs * targets).sum()\n","        FP = ((1-targets) * inputs).sum()\n","        FN = (targets * (1-inputs)).sum()\n","\n","        Tversky = (TP + self.smooth) / (TP + self.alpha*FP + self.beta*FN + smooth)\n","        FocalTversky = (1 - Tversky)**self.gamma\n","\n","        return FocalTversky\n","\n","def fbeta_score(preds, targets, threshold, beta=0.5, smooth=1e-5):\n","    preds_t = torch.where(preds > threshold, 1.0, 0.0).float()\n","    y_true_count = targets.sum()\n","\n","    ctp = preds_t[targets==1].sum()\n","    cfp = preds_t[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n","    \"\"\"\n","    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n","    \"\"\"\n","    y_true_count = targets.sum()\n","    ctp = preds[targets==1].sum()\n","    cfp = preds[targets==0].sum()\n","    beta_squared = beta * beta\n","\n","    c_precision = ctp / (ctp + cfp + smooth)\n","\n","    c_recall = ctp / (y_true_count + smooth)\n","    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n","\n","    return dice\n","\n","def make_infer_mask():\n","    s = cfg.crop_size\n","    f = cfg.crop_fade\n","    x = np.linspace(-1, 1, s)\n","    y = np.linspace(-1, 1, s)\n","    xx, yy = np.meshgrid(x, y)\n","    d = 1 - np.maximum(np.abs(xx), np.abs(yy))\n","    d1 = np.clip(d, 0, f / s * 2)\n","    d1 = d1 / d1.max()\n","    infer_mask = d1\n","    return torch.from_numpy(infer_mask).float().cuda()\n","\n","def mask_to_rle(mask):\n","    m = mask.reshape(-1)\n","\n","    s = np.array((m[:-1] == 0) & (m[1:] == 1))\n","    e = np.array((m[:-1] == 1) & (m[1:] == 0))\n","\n","    s_index = np.where(s)[0] + 2\n","    e_index = np.where(e)[0] + 2\n","    length = e_index - s_index\n","    rle = ' '.join(map(str, sum(zip(s_index, length), ())))\n","    return rle\n","\n","def metric_to_text(ink, label, mask):\n","    text = []\n","    p = ink.reshape(-1)\n","    t = label.reshape(-1)\n","    pos = np.log(np.clip(p,1e-7,1))\n","    neg = np.log(np.clip(1-p,1e-7,1))\n","    bce = -(t*pos +(1-t)*neg).mean()\n","    text.append(f'bce={bce:0.5f}')\n","\n","\n","    mask_sum = mask.sum()\n","\n","    text.append('p_sum  th   prec   recall   fpr   dice   score')\n","    text.append('-----------------------------------------------')\n","    for threshold in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n","        p = ink.reshape(-1)\n","        t = label.reshape(-1)\n","        p = (p > threshold).astype(np.float32)\n","        t = (t > 0.5).astype(np.float32)\n","\n","        tp = p * t\n","        precision = tp.sum() / (p.sum() + 0.0001)\n","        recall = tp.sum() / t.sum()\n","\n","        fp = p * (1 - t)\n","        fpr = fp.sum() / (1 - t).sum()\n","\n","        beta = 0.5\n","        score = beta * beta / (1 + beta * beta) * 1 / recall + 1 / (1 + beta * beta) * 1 / precision\n","        score = 1 / score\n","\n","        dice = 2 * tp.sum() / (p.sum() + t.sum())\n","        p_sum = p.sum()/mask_sum\n","\n","        text.append( f'{p_sum:0.2f}, {threshold:0.2f}, {precision:0.3f}, {recall:0.3f}, {fpr:0.3f},  {dice:0.3f},  {score:0.3f}')\n","\n","    del p, t, tp, precision, recall, fp, fpr, score, dice, p_sum\n","    gc.collect()\n","    text = '\\n'.join(text)\n","    return text\n"],"metadata":{"id":"d7a6k98u6P1G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping():\n","    def __init__(self, patience=0, verbose=0):\n","        self._step = 0\n","        self._score = 0\n","        self._loss = float('inf')\n","        self.patience  = patience\n","        self.verbose = verbose\n","\n","    def loss_validate(self, loss):\n","        if self._loss < loss:\n","            self._step += 1\n","            if self._step > self.patience:\n","                if self.verbose:\n","                    print(f'Training process is stopped early....')\n","                return True\n","        else:\n","            self._step = 0\n","            self._loss = loss\n","\n","    def score_validate(self,score):\n","        if self._score > score:\n","            self._step += 1\n","            if self._step > self.patience:\n","                if self.verbose:\n","                    print(f\"Training process is stopped early....\")\n","                return True\n","        else:\n","            self._step = 0\n","            self._score = score"],"metadata":{"id":"2T3XFmsS6WBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kf = KFold(n_splits=cfg.n_splits, shuffle=False)\n","for fold, (trn_idx, val_idx) in enumerate(kf.split(cfg.train_fragment)):\n","\n","    print(f\" fold {fold+1}/{3}, train data : {cfg.train_fragment[trn_idx]}, valid data : {cfg.train_fragment[val_idx]}\")\n","\n","    train_dataset = CustomTrainDataset(cfg.train_fragment[trn_idx], get_train_transforms())\n","    train_loader = DataLoader(train_dataset, batch_size=cfg.train_batch_size, shuffle=True, pin_memory=True, num_workers=cfg.num_workers, drop_last=False, collate_fn=collate_fn)\n","\n","    valid_dataset = CustomValidDataset(cfg.train_fragment[val_idx], get_valid_transforms())\n","    valid_loader = DataLoader(valid_dataset, batch_size=cfg.valid_batch_size, shuffle=False, pin_memory=True, num_workers=cfg.num_workers, drop_last=False, collate_fn=collate_fn)\n","\n","\n","    scaler = amp.GradScaler()\n","    # criterion = DiceBCELoss()\n","    # criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=1, smooth=1)\n","    # criterion = CompoundLoss()\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    model = Net()\n","    model.to(cfg.device, non_blocking=True)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(\n","            nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(\n","            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","\n","    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=cfg.lr, weight_decay=cfg.wd)\n","\n","    total_samples = len(train_loader)\n","    num_warmup_steps = int((total_samples * cfg.num_epochs * 0.05) / cfg.accumulate_iter)\n","    num_training_steps = total_samples * cfg.num_epochs\n","    lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=int(num_training_steps), num_cycles=0.5)\n","\n","\n","    valid_dic = read_dic(cfg.train_fragment[val_idx][0])\n","    # del valid_dic['mask']\n","    # gc.collect()\n","    H,W = valid_dic['label'].shape\n","    pad0 = (cfg.crop_size - H % cfg.crop_stride)\n","    pad1 = (cfg.crop_size - W % cfg.crop_stride)\n","    valid_label = np.pad(valid_dic['label'], [(0, pad0), (0, pad1)], constant_values=0)\n","    valid_mask = np.pad(valid_dic['mask'], [(0, pad0), (0, pad1)], constant_values=0)\n","    H,W = valid_label.shape\n","    gt_shape = valid_label.shape\n","\n","    # train and validation\n","    del train_dataset, valid_dataset\n","    gc.collect()\n","\n","    best_valid_loss = 9999\n","    best_fbeta = 0\n","    early_stopping = EarlyStopping(patience=cfg.patience, verbose=1)\n","    for epoch in range(1, CFG.num_epochs+1):\n","        model.train()\n","        lrs = lr_scheduler.get_last_lr()[0]\n","        cur_lr = f\"LR : {lrs:.7f}\"\n","        pbar_train = enumerate(train_loader)\n","        pbar_train = tqdm(pbar_train, total=len(train_loader), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n","        mloss_train, mloss_val, val_metric = 0.0, 0.0, 0.0\n","\n","        for i, batch in pbar_train:\n","            for k, v in batch.items():\n","                batch[k] = v.to(cfg.device, non_blocking=True)\n","            label = batch['labels'].unsqueeze(1)\n","            with amp.autocast(enabled=True):\n","                output = model(batch)\n","                loss = criterion(output['logit'], label)\n","            loss = loss / cfg.accumulate_iter\n","            scaler.scale(loss).backward()\n","\n","            if ((i + 1) % cfg.accumulate_iter == 0) or (i + 1 == len(train_loader)):\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad(set_to_none=True)\n","\n","                if cfg.batch_scheduler:\n","                    lr_scheduler.step()\n","\n","            mloss_train += loss.item() * cfg.accumulate_iter\n","\n","            gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n","            pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{CFG.num_epochs}\", gpu_mem, cur_lr,\n","                                                                  f\"Loss: {mloss_train / (i + 1):.4f}\"))\n","\n","\n","        model.eval()\n","        pbar_val = enumerate(valid_loader)\n","        pbar_val = tqdm(pbar_val, total=len(valid_loader), bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n","\n","\n","        infer_mask = make_infer_mask()\n","        final_pred_mask = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n","        count = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n","\n","        for i, batch in pbar_val:\n","            for k, v in batch.items():\n","                batch[k] = v.to(cfg.device, non_blocking=True)\n","            label = batch['labels'].unsqueeze(1)\n","            xys = batch['xys']\n","\n","            with torch.no_grad():\n","                with torch.cuda.amp.autocast(enabled=True):\n","                    output = model(batch)\n","                    pred_masks = output['ink']\n","                    loss = criterion(output['logit'], label)\n","                    mloss_val += loss.item()\n","\n","            for j, xy in enumerate(xys):\n","                final_pred_mask[xy[1]:xy[3], xy[0]:xy[2]] += pred_masks[j, 0] * infer_mask\n","                count[xy[1]:xy[3], xy[0]:xy[2]] += infer_mask\n","\n","            pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n","\n","        final_pred_mask = final_pred_mask/(count+0.000001)\n","        final_pred_mask = final_pred_mask[:H,:W]\n","        final_pred_mask = final_pred_mask*torch.from_numpy(valid_mask).float().cuda()\n","\n","        best_th = 0\n","        temp_best_fbeta = 0\n","\n","        for threshold in np.arange(0.2, 0.75, 0.05):\n","            temp_fbeta = fbeta_score(final_pred_mask, torch.from_numpy(valid_label), threshold)\n","\n","            if np.round(threshold,8) == 0.5:\n","                fbeta = temp_fbeta\n","                if fbeta>temp_best_fbeta:\n","                    temp_best_fbeta = fbeta\n","                    best_th = threshold\n","            print(f\"Threshold : {threshold:.2f}\\tFBeta : {temp_fbeta:.6f}\")\n","        if best_fbeta < temp_best_fbeta:\n","            print(f\"best_th : {best_th:.2f}\\tFBeta : {temp_best_fbeta:.6f}\")\n","\n","            pred_mask = final_pred_mask.detach().cpu().numpy()\n","            plt.figure(figsize=(20, 16))\n","            plt.subplot(1,3,1)\n","            plt.title(f\"image\")\n","            plt.imshow(pred_mask)\n","\n","            plt.subplot(1,3,2)\n","            plt.title(f\"pred_ink\")\n","            plt.imshow(np.where(pred_mask>0.5,1,0))\n","\n","            plt.subplot(1,3,3)\n","            plt.title(f\"labels\")\n","            plt.imshow(valid_dic['label'])\n","            plt.show()\n","\n","            print(metric_to_text(pred_mask, valid_label, valid_mask))\n","\n","            print(f\"{g_}Validation Score Increased from {best_fbeta} to {temp_best_fbeta}{sr_}\")\n","            print('best valid loss achieved')\n","            best_valid_loss = mloss_val\n","            if not os.path.exists(cfg.colab_dir + f'/model/{cfg.model_name}'):\n","                os.mkdir(cfg.colab_dir + f'/model/{cfg.model_name}')\n","            torch.save(model.state_dict(),f\"{cfg.colab_dir}/model/{cfg.model_name}/fold_{fold}_{cfg.model_name}_{cfg.date}.pt\")\n","\n","            best_fbeta = temp_best_fbeta\n","\n","    #     if (epoch%10) == 0:\n","    #         print(metric_to_text(final_pred_mask.detach().cpu().numpy(), valid_dic[\"label\"], valid_dic['mask']))\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        if early_stopping.score_validate(best_fbeta):\n","            break\n","\n","        print()\n","    del train_loader, valid_loader, valid_dic\n","    gc.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1e9gmpfHAb-c5CYMmocDVbqOZbTnyiqh8"},"id":"DSYrZS9x6Woo","outputId":"0526d0f9-3877-4c55-eef7-94e70a3ecd77"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# H,W = valid_dic['label'].shape\n","# pad0 = (cfg.crop_size - H % cfg.crop_stride)\n","# pad1 = (cfg.crop_size - W % cfg.crop_stride)\n","# valid_label = np.pad(valid_dic['label'], [(0, pad0), (0, pad1)], constant_values=0)\n","# gt_shape = valid_label.shape"],"metadata":{"id":"h1290XMz2TPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# H, W = valid_dic['label'].shape\n","\n","# infer_mask = make_infer_mask()\n","# final_pred_mask = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n","# count = torch.zeros(gt_shape, dtype=torch.float32, device='cuda')\n","\n","# for i, batch in pbar_val:\n","#     for k, v in batch.items():\n","#         batch[k] = v.to(cfg.device, non_blocking=True)\n","# #         xys = batch['xys']\n","#     label = batch['labels'].unsqueeze(1)\n","# #         mask = batch['masks']\n","#     xys = batch['xys']\n","\n","#     with torch.no_grad():\n","#         with torch.cuda.amp.autocast(enabled=True):\n","#             output = model(batch)\n","#             pred_masks = output['ink']\n","#             loss = criterion(output['logit'], label)\n","#             mloss_val += loss.item()\n","# #             mloss_val += criterion(pred_masks, label.unsqueeze(1)).item()\n","# #             pred_masks = torch.sigmoid(pred_masks)\n","\n","#     for j, xy in enumerate(xys):\n","#         final_pred_mask[xy[1]:xy[3], xy[0]:xy[2]] += pred_masks[j, 0] * infer_mask\n","#         # count[xy[1]:xy[3], xy[0]:xy[2]] += infer_mask\n","\n","#     pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n","\n","# # final_pred_mask = final_pred_mask/(count+0.000001)\n","# final_pred_mask = final_pred_mask[:H,:W]\n","# final_pred_mask = final_pred_mask*torch.from_numpy(valid_dic['mask']).float().cuda()"],"metadata":{"id":"Zd_MXbc9vF-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for threshold in np.arange(0.2, 0.75, 0.05):\n","#     temp_fbeta = fbeta_score(final_pred_mask, torch.from_numpy(valid_dic['label']), threshold)\n","#     print(temp_fbeta)"],"metadata":{"id":"atUxppJA31yx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pred_mask = final_pred_mask.detach().cpu().numpy()\n","# plt.figure(figsize=(20, 16))\n","# plt.subplot(1,3,1)\n","# plt.title(f\"image\")\n","# plt.imshow(pred_mask)\n","\n","# plt.subplot(1,3,2)\n","# plt.title(f\"pred_ink\")\n","# plt.imshow(np.where(pred_mask>0.5,1,0))\n","\n","# plt.subplot(1,3,3)\n","# plt.title(f\"labels\")\n","# plt.imshow(valid_dic['label'])\n","# plt.show()"],"metadata":{"id":"fMnWHPo64GV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fold1 - cv.0.639 valid 2a\n","# fold2 - cv 0.651 valid 2b\n","# fold3 - cv 0.653 valid 2c\n","# fold4 - cv 0.624 valid 3\n","# fold5 - cv 0.646   valid 1"],"metadata":{"id":"m_WUR-GKG8L8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fold1 -cv  0.634\n","# 16 - 23 1\n","# 17 - 24 2\n","# 18 - 25 3\n","# 19 - 26 4 - 높아짐\n","# 20 - 27 5\n","# 21 - 28 6\n","# 22 - 29 7\n","# 23 - 30 8\n","# 24 - 31 9\n","# 25 - 32 10\n","# 26 - 33 11\n"],"metadata":{"id":"PWlWxnRAQAA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# def do_random_cutmix(\n","#     self,\n","#     image,\n","#     label,\n","#     mask,\n","#     index,\n","#     valid_mask_threshold=0.8,\n","#     valid_label_threshold=0.1,\n","#     mode = 'mask'\n","#     ):\n","#     w, h = image.shape[:2]\n","#     ws = w // 2\n","#     hs = h // 2\n","\n","#     xc, yc = [int(random.uniform(w*0.35, h*0.65)) for _ in range(2)]\n","#     indexes = [index] + [random.randint(0, index) for _ in range(3)]\n","\n","\n","#     result_img = np.full((imsize, imsize, 3), 1, dtype=np.float32)\n","\n","#     for i, index in enumerate(indexes):\n","#         image = load_image(path, index)\n","\n","#         #top left\n","#         if i == 0:\n","#             x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n","#             x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n","#         elif i == 1:  # top right\n","#             x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n","#             x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n","#         elif i == 2:  # bottom left\n","#             x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n","#             x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n","#         elif i == 3:  # bottom right\n","#             x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n","#             x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n","\n","#         result_img[y1a:y2a, x1a:x2a] = image[y1b:y2b, x1b:x2b]\n","\n","#     return result_img"],"metadata":{"id":"wTNABRjJ7EVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P-nc4OSSNIQW"},"execution_count":null,"outputs":[]}]}